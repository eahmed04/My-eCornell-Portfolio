{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Preparing a Data Set for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will practice the second and third steps of the machine learning life cycle and begin preparing data so that it can be used to train a machine learning model that solves a regression problem. Note that by the end of the exercise, your data set wont be completely ready for the modeling phase, but you will gain experience using some common data preparation techniques. You will complete the following tasks to transform your data:\n",
    "\n",
    "1. Build your data matrix (DataFrame) and define your ML Problem:\n",
    "    * Load the \"Census Income\" data set into a DataFrame and inspect the data\n",
    "    * Define the label - what are you predicting?\n",
    "    * Identify features\n",
    "2. Clean your data:\n",
    "    * Handle outliers by building a new regression label column by winsorizing outliers\n",
    "    * Handle missing data by replacing all missing values in the dataset with means\n",
    "3. Explore your data:\n",
    "    * Identify two features with the highest correlation with label\n",
    "    * Build appropriate bivariate plots to visualize the correlations between features and the label \n",
    "4. Analysis:\n",
    "    * Analyze feature engineering techniques that should be used to prepare the data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Build Your Data Matrix (DataFrame) and Define Your ML Problem\n",
    "\n",
    "<b>Note</b>: for the purpose of this course, we will use data matrix and DataFrame interchangeably. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "So far, in these exercises, we have been using a small subset of the \"Census income\" dataset. We will now use a version that has a substantially greater number of rows, but the same number of columns as before. You will see this reflected when you print out the dimensions of your DataFrame after you load your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the specified file name to load the data. Save it as a Pandas DataFrame called `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Read in the data using the `pd.read_csv()` function and save it to DataFrame `df`. <i>Note<i>: use the variable `filename` in your call to `pd.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not remove or edit the line below:\n",
    "filename = os.path.join(os.getcwd(), \"data\", \"censusData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Display the shape of `df` -- that is, the number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Check your work*: while we used a small subset of the Census dataset in the exercises, the dataset that we are using now has a substantially greater number of rows, but the same number of columns as before. You should see this reflected when you print out the dimensions of DataFrame `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Get a peek of the data by displaying the first few rows, as you usually do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Define the Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that your goal is to train a machine learning model that predicts the number of years of education that a person has had. This is an example of supervised learning and is a regression problem; it requires a label that contains real or continuous numbers. In our dataset, our label will be the `education-num` column. Let's inspect the values in the `education-num` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education-num']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, our features will be all of the remaining columns in the dataset. \n",
    "\n",
    "**Task**: In the code cell below, create a list containing the features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Clean Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of data preparation involves cleaning \"dirty\" data. Two common data cleaning techniques involve the handling of outliers and missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Handle Outliers\n",
    "\n",
    "Let us prepare the data in our label column. Namely, we will detect and replace outliers in the data using winsorization.\n",
    "\n",
    "We will create a new version of the `education-num` column, in which we replace the outlier values of `education-num` (on both sides of the range -- the low end as well as the high end). We will replace the outliers with the corresponding percentile value, as we did in the exercises. That is, if we wish to replace any value below, say, the 1.234-th percentile, we shall replace all such values by the exact same value in our data -- the value such that 1.234% of data lies below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to import the `stats` module from the `scipy` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Create a new column, titled `education_years` by winsorizing the `education-num` column with the top and bottom 1% percentile values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that a new column got added to the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting thing to think about: take a look at the data and notice that for the first five rows, the values of the `education-num` column and its winsorized version -- `education_years` -- are the same. Does this mean that winsorization did not work? Or are there discrepancies further down the list of rows, where we cannot see them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Check that the values of `education-num` and `education_years` are *not* identical. You may do this by subtracting the two columns and then listing the unique values of the result. If you see values other than zero, it means *some* change did happen, as we would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Handle Missing Data\n",
    "\n",
    "Next, we are going to find missing values in our entire dataset and impute the missing values by\n",
    "replacing them with means. This process is a common task in feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Identifying missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Check if a given value in any data cell is missing, and sum up the resulting values (`True`/`False`) by columns. Assign the results to variable `nan_count`. Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count = # YOUR CODE HERE\n",
    "\n",
    "nan_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing the missing values with the mean only makes sense for the numerically valued columns (and not for strings). Hence, we will focus on the `age` and `hours-per-week` columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keeping record of the missingness: creating dummy variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, you will now create dummy variables indicating missingness of the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Store the `True`/`False` series that indicate missingness of any value in `age` as a new column called `age_na`. Store the `True`/`False` series that indicate missingness of every value of `hours-per-week` as a new column called `hours-per-week_na`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing the missing values with mean values of the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Fill the missing values of the `age` and `hours-per-week` columns with the mean value of the corresponding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Check your results. Display the sum of missing values in the `age` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Explore Your Data \n",
    "\n",
    "You will now perform exploratory data analysis in preparation for selecting your features as part of feature engineering. So far we identified all columns in the dataset to serve as features, but not all features may be suitable for our machine learning problem. While feature engineering involves transforming your features into proper formats (e.g. transforming numerical data into binary values), it also includes selecting appropriate features for modeling. By exploring your data, you will identify trends, patterns, and interdependence among features and the label. This will enable you to choose the appropriate features to use for training your machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify Correlations\n",
    "In particular, we will focus on identifying which features in the data have the highest correlation with the label. In the next few cells, we will demonstrate how to use Pandas `corr()` method to get a list of correlation coefficients between the `label` and all other numerical features.  To learn more about the `corr()` method, consult the online [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first galnce at what the `corr()` method does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a computed *correlation matrix*. The values on the diagonal are all equal to 1 because they represent the correlations between each column with itself. The matrix is symmetrical with respect to the diagonal.<br>\n",
    "\n",
    "We only need to observe correlations of all features with the column `education_years` (as opposed to every possible pairwise correlation). Se let's query the `education_years` column of this matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['education_years']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good, but contains two values too many: we do not need to observe the correlation of `education_years` with itself, and moreover we are not interested in the correlation between the label and `education-num` (recall that `education_years` is a winsorized version of the `education-num`). So we will exclude these two values using the Pandas `drop()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['education_years','education-num']\n",
    "df.corr()['education_years'].drop(exclude, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: The code below performs the same operation above, but saves the result to variable `corrs`. Sort the values in `corrs` in descending order. Use the Pandas method `sort_values()`  to accomplish this task. For more information on how to use the `sort_values()` method, consult the online [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not remove or edit the line below:\n",
    "corrs = df.corr()['education_years'].drop(exclude, axis = 0)\n",
    "\n",
    "corrs_sorted = # YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Use Pandas indexing to extract the *column names* for the top two correlation values and save to a Python list called `top_two_corr`. <br>\n",
    "_Tip_: `corrs_sorted` is a Pandas `Series` object, in which column names are the *index*. Once you find the column names, use the Python `list()` method to convert the values into a Python `list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_two_corr = # YOUR CODE HERE \n",
    "\n",
    "top_two_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have identified the two features that have the highest correlation with the label, let us find the correlation between both features.\n",
    "\n",
    "**Task**: Use the `corr()` method to find the correlation between the two features. Save the result to variable `corr_features`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features = # YOUR CODE HERE \n",
    "\n",
    "corr_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bivariate Plotting: Produce Plots for the Label and Its Top Correlates\n",
    "\n",
    "Let us visualize our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `scatterplot()` function in `seaborn` to plot the relationships between the two features we just identified and the label. For more information about the function, consult the online [documentation](https://seaborn.pydata.org/generated/seaborn.scatterplot.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a DataFrame named ` df_corr1` that contains two columns from DataFrame `df`: the label, and the first of the two columns which correlate with it the most:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_corr1 = pd.DataFrame({'hours per week': df['hours-per-week'], 'education_years': df['education_years']})\n",
    "df_corr1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Create a `seaborn` scatterplot of the new DataFrame that you just created. Since our DataFrame has thousands of rows, only plot the first 50 rows to better visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Now create a DataFrame named ` df_corr2` that contains two columns from DataFrame `df`: the label, and the second of the two columns which correlate with it the most. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr2 = # YOUR CODE HERE\n",
    "\n",
    "df_corr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Create a `seaborn` scatterplot of the new DataFrame that you just created. Once again, only plot the first 50 rows to better visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Now let's visualize the correlation between both features. Create a DataFrame named ` df_corr3` that contains two columns from DataFrame `df`: the two feature columns that correlate most with the label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr3 = # YOUR CODE HERE\n",
    "\n",
    "df_corr3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Create a `seaborn` scatterplot of the new DataFrame that you just created. One again, only plot the first 50 rows to better visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have been visualizing a subset of the data. Let's now create a visualization of all of the data.\n",
    "\n",
    "**Task**: Create a DataFrame named ` df_corrs` that contains these three columns from DataFrame `df`: the label, and the two columns which correlate with it the most.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_corrs = # YOUR CODE HERE\n",
    "\n",
    "df_corrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `pairplot()` function in `seaborn` to plot the data in `df_corrs`. For more information about the function, consult the online [documentation](https://seaborn.pydata.org/generated/seaborn.pairplot.html).\n",
    "\n",
    "<b>Task</b>: To better visualize the data and prevent overlapping of data points, call the `pairplot()` function with the following parameters:\n",
    "* Use `kind = 'kde'` to specify the *kernel density estimator* as the *kind* of the plot.\n",
    "* Use `corner=True` to make sure you don't plot redundant (symmetrical) plots.\n",
    "\n",
    "Note: This will take a few minutes to run and produce a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about the possible interpretations of this plot. Here is an example of the kind of stories this data seems to be telling. It appears as though hours per week are stacked around the typical 40-hour value, and that this value of weekly hours dominates regardless of the level of education. However, it seems that it is somewhat less typical for people with lower levels of formal education to be working over 65 hours a week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Analysis\n",
    "\n",
    "1. Based on what you have learned in this unit, try to interpret what you have discovered about the relationships between the features and the label in this exercise. Are the top two correlated features strongly or weakly correlated with the label? What about the remaining features? Are the two features strongly or weakly correlated with each other? Based on these answers, do these features seem appropriate to use for our machine learning problem? Are there other considerations that should be taken when selecting features for this problem (e.g. selecting different data, removing/adding features)?\n",
    "\n",
    "2. Inspect the data in your data matrix. Describe other feature engineering techniques that should be used to make the data suitable for modeling.\n",
    "\n",
    "Record your findings in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Double click this Markdown cell to make it editable, and record your findings here.>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
